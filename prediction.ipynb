{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from FaceRecognitionModel import FaceRecognition,get_device\n",
    "# from FaceVerificationModel import FaceVerification,get_device\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomRotation, ColorJitter,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'lfw_funneled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folders = os.listdir(folder_path)\n",
    "data_path = []\n",
    "for path in image_folders:\n",
    "    if '.' not in path:\n",
    "        image_path = os.path.join(folder_path,path)\n",
    "    if len(os.listdir(image_path)) >= 2:\n",
    "        data_path.append(image_path)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Face_verification_Final\\FaceRecognitionModel.py:109: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return x.to(get_device())\n"
     ]
    }
   ],
   "source": [
    "FaceRecognition = FaceRecognition().to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaif Khan\\AppData\\Local\\Temp\\ipykernel_22512\\3631116834.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  FaceRecognition.load_state_dict(torch.load('face_recognition_triplet2.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FaceRecognition.load_state_dict(torch.load('face_recognition_triplet2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FaceRecognition(\n",
       "  (embedding): CNN(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear1): Linear(in_features=30976, out_features=1024, bias=True)\n",
       "    (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (output): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FaceRecognition.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(embedding1, embedding2):\n",
    "    return F.pairwise_distance(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = data_path[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions, labels = [],[]\n",
    "# prediction_true,prediction_false = 0,0\n",
    "# total_data = 0\n",
    "# for path1,path2 in zip(data_path[:len(data_path)-1], data_path[1:]):\n",
    "#     images1 = os.listdir(path1)\n",
    "#     images2 = os.listdir(path2)\n",
    "\n",
    "#     anchor_image = Image.open(os.path.join(path1,images1[0]))\n",
    "#     positive_image = Image.open(os.path.join(path1,images1[1]))\n",
    "#     negative_image = Image.open(os.path.join(path2,images2[0]))\n",
    "\n",
    "#     anchor_embedding = FaceRecognition(transform(anchor_image).to(get_device()))\n",
    "#     positive_embedding = FaceRecognition(transform(positive_image).to(get_device()))\n",
    "#     negative_embedding = FaceRecognition(transform(negative_image).to(get_device()))\n",
    "\n",
    "#     same_dist = calculate_distance(anchor_embedding,positive_embedding)\n",
    "#     diff_dist = calculate_distance(anchor_embedding,negative_embedding)\n",
    "#     total_data += 2\n",
    "#     predictions.append(same_dist)\n",
    "#     predictions.append(diff_dist)\n",
    "\n",
    "#     labels.append(1)\n",
    "#     labels.append(0)\n",
    "\n",
    "#     if same_dist <= 0.5:\n",
    "#         prediction_true += 1\n",
    "#     else:\n",
    "#         prediction_false += 1\n",
    "\n",
    "#     if diff_dist > 0.5:\n",
    "#         prediction_true += 1\n",
    "#     else:\n",
    "#         prediction_false += 1\n",
    "# print(f\"accuracy of model is {prediction_true/total_data:.2f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 0.79\n"
     ]
    }
   ],
   "source": [
    "# Open files for writing predictions and labels\n",
    "best_threshold = 1.0\n",
    "with open('predictions.txt', 'w') as pred_file, open('labels.txt', 'w') as label_file:\n",
    "    prediction_true, prediction_false = 0, 0\n",
    "    total_data = 0\n",
    "\n",
    "    for path1, path2 in zip(data_path[:len(data_path)-1], data_path[1:]):\n",
    "        images1 = os.listdir(path1)\n",
    "        images2 = os.listdir(path2)\n",
    "\n",
    "        anchor_image = Image.open(os.path.join(path1, images1[0]))\n",
    "        positive_image = Image.open(os.path.join(path1, images1[1]))\n",
    "        negative_image = Image.open(os.path.join(path2, images2[0]))\n",
    "\n",
    "        anchor_embedding = FaceRecognition(transform(anchor_image).unsqueeze(0).to(get_device()))\n",
    "        positive_embedding = FaceRecognition(transform(positive_image).unsqueeze(0).to(get_device()))\n",
    "        negative_embedding = FaceRecognition(transform(negative_image).unsqueeze(0).to(get_device()))\n",
    "\n",
    "        same_dist = calculate_distance(anchor_embedding, positive_embedding)\n",
    "        diff_dist = calculate_distance(anchor_embedding, negative_embedding)\n",
    "        total_data += 2\n",
    "\n",
    "        # Write predictions and labels to files\n",
    "        pred_file.write(f\"{same_dist.item()}\\n\")\n",
    "        pred_file.write(f\"{diff_dist.item()}\\n\")\n",
    "        label_file.write(\"1\\n\")\n",
    "        label_file.write(\"0\\n\")\n",
    "\n",
    "        if same_dist <= best_threshold:\n",
    "            prediction_true += 1\n",
    "        else:\n",
    "            prediction_false += 1\n",
    "\n",
    "        if diff_dist > best_threshold:\n",
    "            prediction_true += 1\n",
    "        else:\n",
    "            prediction_false += 1\n",
    "\n",
    "    print(f\"Accuracy of the model is {prediction_true/total_data:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction, label, total :-  2654 704 3358\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction, label, total :- \",prediction_true,prediction_false,total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data == prediction_true+prediction_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of model is 0.7904\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy of model is {prediction_true/total_data:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1220  245]\n",
      " [ 459 1434]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize confusion matrix components\n",
    "TP, TN, FP, FN = 0, 0, 0, 0\n",
    "\n",
    "# Read predictions and labels from the files\n",
    "with open('predictions.txt', 'r') as pred_file, open('labels.txt', 'r') as label_file:\n",
    "    predictions = [float(line.strip()) for line in pred_file.readlines()]\n",
    "    labels = [int(line.strip()) for line in label_file.readlines()]\n",
    "\n",
    "# Iterate over predictions and labels to compute TP, TN, FP, FN\n",
    "for pred, label in zip(predictions, labels):\n",
    "    if label == 1 and pred <= best_threshold:\n",
    "        TP += 1\n",
    "    elif label == 0 and pred > best_threshold:\n",
    "        TN += 1\n",
    "    elif label == 0 and pred <= best_threshold:\n",
    "        FP += 1\n",
    "    elif label == 1 and pred > best_threshold:\n",
    "        FN += 1\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix:\n",
    "# [[ 720  339]\n",
    "#  [ 959 1340]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "TP (True Positives): 1220\n",
      "FP (False Positives): 245\n",
      "FN (False Negatives): 459\n",
      "TN (True Negatives): 1434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Read predictions and labels from the files\n",
    "with open('predictions.txt', 'r') as pred_file, open('labels.txt', 'r') as label_file:\n",
    "    predictions = [float(line.strip()) for line in pred_file.readlines()]\n",
    "    labels = [int(line.strip()) for line in label_file.readlines()]\n",
    "\n",
    "# Convert predictions to binary labels using your threshold\n",
    "threshold = best_threshold\n",
    "binary_predictions = [1 if pred <= threshold else 0 for pred in predictions]\n",
    "\n",
    "# Compute confusion matrix using sklearn\n",
    "cm = confusion_matrix(labels, binary_predictions, labels=[1, 0])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"TP (True Positives): {cm[0, 0]}\")\n",
    "print(f\"FP (False Positives): {cm[1, 0]}\")\n",
    "print(f\"FN (False Negatives): {cm[0, 1]}\")\n",
    "print(f\"TN (True Negatives): {cm[1, 1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3358"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1651+1619+60+28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'val'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m imageFolders \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m dataPath \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m imageFolders:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'val'"
     ]
    }
   ],
   "source": [
    "imageFolders = os.listdir(folder_path)\n",
    "dataPath = []\n",
    "for folder in imageFolders:\n",
    "    dataPath.append(os.path.join(folder_path,folder))\n",
    "dataPath[0],len(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = transforms.Compose([\n",
    "    transforms.Resize((200,200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.Resize((200,200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomRotation(10),\n",
    "    ColorJitter(brightness=0.2,contrast=0.2,saturation=0.2, hue=0.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = []\n",
    "for path1, path2 in zip(dataPath[:len(dataPath)-1], dataPath[1:]):\n",
    "    \n",
    "    images1 = os.listdir(path1)\n",
    "    images2 = os.listdir(path2)\n",
    "    # length = 0\n",
    "\n",
    "    # if(len(images1) < len(images2)):\n",
    "    #     length = len(images1)\n",
    "    # else:\n",
    "    #     length = len(images2)\n",
    "\n",
    "    # if length < 10:\n",
    "    #     print(length)\n",
    "    #     length = 10\n",
    "    # else:\n",
    "    #     print(length)\n",
    "    length = 20\n",
    "    for i,j in zip(images1[:length], images2[:length]):\n",
    "        anchorImage = Image.open(os.path.join(path1,images1[0]))\n",
    "        positiveImage = Image.open(os.path.join(path1,i))\n",
    "        negaiveImage = Image.open(os.path.join(path2,j))\n",
    "\n",
    "        anchor = transform1(anchorImage)\n",
    "        positive = transform1(positiveImage)\n",
    "        negative = transform1(negaiveImage)\n",
    "\n",
    "        training.append([anchor, positive, negative])\n",
    "len(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path1, path2 in zip(dataPath[:len(dataPath)-1], dataPath[1:]):\n",
    "    \n",
    "    images1 = os.listdir(path1)\n",
    "    images2 = os.listdir(path2)\n",
    "    # length = 0\n",
    "\n",
    "    # if(len(images1) < len(images2)):\n",
    "    #     length = len(images1)\n",
    "    # else:\n",
    "    #     length = len(images2)\n",
    "\n",
    "    # if length < 10:\n",
    "    #     print(length)\n",
    "    #     length = 10\n",
    "    # else:\n",
    "    #     print(length)\n",
    "    length = 10\n",
    "    for i,j in zip(images1[:length], images2[:length]):\n",
    "        anchorImage = Image.open(os.path.join(path1,images1[0]))\n",
    "        positiveImage = Image.open(os.path.join(path1,i))\n",
    "        negaiveImage = Image.open(os.path.join(path2,j))\n",
    "\n",
    "        anchor = transform2(anchorImage)\n",
    "        positive = transform2(positiveImage)\n",
    "        negative = transform2(negaiveImage)\n",
    "\n",
    "        training.append([anchor, positive, negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 200, 200])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 0.60\n"
     ]
    }
   ],
   "source": [
    "with open('predictions.txt', 'w') as pred_file, open('labels.txt', 'w') as label_file:\n",
    "    prediction_true, prediction_false = 0, 0\n",
    "    total_data = 0\n",
    "    for data in training:\n",
    "        anchor_embedding = FaceRecognition(data[0].unsqueeze(0).to(get_device()))\n",
    "        positive_embedding = FaceRecognition(data[1].unsqueeze(0).to(get_device()))\n",
    "        negative_embedding = FaceRecognition(data[2].unsqueeze(0).to(get_device()))\n",
    "\n",
    "        same_dist = calculate_distance(anchor_embedding, positive_embedding)\n",
    "        diff_dist = calculate_distance(anchor_embedding, negative_embedding)\n",
    "        total_data += 2\n",
    "\n",
    "        # Write predictions and labels to files\n",
    "        pred_file.write(f\"{same_dist.item()}\\n\")\n",
    "        pred_file.write(f\"{diff_dist.item()}\\n\")\n",
    "        label_file.write(\"1\\n\")\n",
    "        label_file.write(\"0\\n\")\n",
    "\n",
    "        if same_dist <= best_threshold:\n",
    "            prediction_true += 1\n",
    "        else:\n",
    "            prediction_false += 1\n",
    "\n",
    "        if diff_dist > best_threshold:\n",
    "            prediction_true += 1\n",
    "        else:\n",
    "            prediction_false += 1\n",
    "\n",
    "    print(f\"Accuracy of the model is {prediction_true/total_data:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3358"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix:\n",
    "# TP (True Positives): 1220\n",
    "# FP (False Positives): 245\n",
    "# FN (False Negatives): 459\n",
    "# TN (True Negatives): 1434\n",
    "\n",
    "1220+1434+245+459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "TP (True Positives): 687\n",
      "FP (False Positives): 347\n",
      "FN (False Negatives): 1083\n",
      "TN (True Negatives): 1423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Read predictions and labels from the files\n",
    "with open('predictions.txt', 'r') as pred_file, open('labels.txt', 'r') as label_file:\n",
    "    predictions = [float(line.strip()) for line in pred_file.readlines()]\n",
    "    labels = [int(line.strip()) for line in label_file.readlines()]\n",
    "\n",
    "# Convert predictions to binary labels using your threshold\n",
    "threshold = best_threshold\n",
    "binary_predictions = [1 if pred <= threshold else 0 for pred in predictions]\n",
    "\n",
    "# Compute confusion matrix using sklearn\n",
    "cm = confusion_matrix(labels, binary_predictions, labels=[1, 0])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"TP (True Positives): {cm[0, 0]}\")\n",
    "print(f\"FP (False Positives): {cm[1, 0]}\")\n",
    "print(f\"FN (False Negatives): {cm[0, 1]}\")\n",
    "print(f\"TN (True Negatives): {cm[1, 1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
